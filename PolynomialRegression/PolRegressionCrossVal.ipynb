{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión polinomial.**\n",
    "\n",
    "*Uso de la validación cruzada (método del gradiente).*\n",
    "\n",
    "Hello, I'm Go1234550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos una regresión lineal múltiple para predecir el precio de una casa haciendo uso de las siguientes variables:\n",
    "\n",
    "* sqft_living(pies cuadrados de área habitable): Indica el área total, en pies cuadrados, de la superficie habitable de una vivienda.\n",
    "\n",
    "* bedrooms: Numero de cuartos que cuenta la vivienda.\n",
    "\n",
    "Se consideran estas variables ya que son las que tienen mayor influencia para la determinación del precio de una propiedad.\n",
    "\n",
    "Dataset utilizado: https://www.kaggle.com/code/laeclover/predicci-n-de-venta-de-casa/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos las librerías.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creamos la regresión múltiple.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la clase de nuestra regresión múltiple junto a sus métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iter=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X to account for the intercept\n",
    "        x_with_intercept = np.column_stack((np.ones(len(X)), X))\n",
    "\n",
    "        # Initialize the random coefficients\n",
    "        self.coef_ = np.random.rand(x_with_intercept.shape[1])\n",
    "\n",
    "        # Gradient descent\n",
    "        for _ in range(self.n_iter):\n",
    "            gradient = -2 * x_with_intercept.T @ (y - x_with_intercept @ self.coef_)\n",
    "            self.coef_ -= self.learning_rate * gradient\n",
    "\n",
    "        # The first coefficient is the intercept\n",
    "        self.intercept_ = self.coef_[0]\n",
    "        self.coef_ = self.coef_[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X to account for the intercept\n",
    "        x_with_intercept = np.column_stack((np.ones(len(X)), X))\n",
    "        return x_with_intercept @ np.concatenate(([self.intercept_], self.coef_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizamos el Train-Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos que utilizaremos, considerando un 60% para el conjunto de entrenamiento y 40% para el de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CSV file to read the data\n",
    "#sqft_living = column 5\n",
    "x1 = pd.read_csv('kc_house_data.csv', usecols=[5])\n",
    "#bedrooms = column 3\n",
    "x2 = pd.read_csv('kc_house_data.csv', usecols=[3])\n",
    "#price = column 2\n",
    "y = pd.read_csv('kc_house_data.csv', usecols=[2])\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "x1 = x1.to_numpy()\n",
    "x2 = x2.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "# Determinate the size of the training set(60%) and the test set(40%)\n",
    "training_set_size = int(0.6 * len(x1)) #x1 because it has the same length as x2 and y\n",
    "test_set_size = len(x1) - training_set_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementación de la validación cruzada.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la validación cruzada, seleccionando aleatoriamente los datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "#Shuffle the data\n",
    "data = list(zip(x1, x2, y))\n",
    "rd.shuffle(data)\n",
    "x1, x2, y = zip(*data)\n",
    "\n",
    "#Split the data into training set\n",
    "x1_train = np.array(x1[:training_set_size])\n",
    "x2_train = np.array(x2[:training_set_size])\n",
    "y_train = np.array(y[:training_set_size])\n",
    "\n",
    "#Split the data into test set\n",
    "x1_test = np.array(x1[training_set_size:])\n",
    "x2_test = np.array(x2[training_set_size:])\n",
    "y_test = np.array(y[training_set_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento del modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = MultipleRegression(learning_rate=0.001, n_iter=10000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(np.column_stack((x1_train, x2_train)), y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(np.column_stack((x1_test, x2_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
